---
title: "Global Minimum Volatility portfolio (GMV) on an equity portfolio"
output: html_document
date: "`r Sys.Date()`"
editor_options: 
  markdown: 
    wrap: 72
---

# 1. Introduction

## 1.1 Packages

We import the necessary libraries to perform the first analysis.

1.  library(tidyverse): The tidyverse package constitutes a collection
    of R packages meticulously designed to work seamlessly in unison for
    data manipulation, visualization, and analysis. It encompasses
    packages like ggplot2 for data visualization, dplyr for data
    manipulation, tidyr for data tidying, and more. Loading tidyverse
    avails all these packages for utilization during your R session,
    streamlining your data analysis workflow.

2.  library(quantmod): The quantmod package primarily caters to
    quantitative financial modeling and analysis. It furnishes an array
    of functions and tools for handling financial data, such as
    downloading and managing stock price data, conducting technical
    analysis, and modeling financial time series.

3.  library(DataExplorer): The DataExplorer package serves the purpose
    of preliminary data exploration and analysis. It offers functions to
    generate summary statistics, visualize missing data, plot variable
    distributions, and more. It can aid in obtaining a quick overview of
    your data before delving into more extensive analyses.

4.  library(corrplot): The corrplot package specializes in visualizing
    correlation matrices. It provides functions for generating visually
    appealing and informative correlation plots, which prove valuable
    for comprehending relationships between variables within your data.

5.  library(scales): The scales package provides an assortment of scales
    and formatting functions tailored for R graphics. It is often
    employed in conjunction with other plotting packages, such as
    ggplot2, to customize the appearance of plots, including axes,
    labels, and color scales.

```{r}
library(tidyverse)
library(quantmod)
library(DataExplorer)
library(corrplot)
library(scales)
```

## 1.2 Investment universe

In our portfolio management project, we have carefully chosen a set of
twenty stocks from a larger universe of investments. This selection
represents the most significant companies in the US equity market,
primarily based on their market capitalization. By analyzing these
stocks, our objective is to gain valuable insights into the strategies
that can be employed for managing investments in the US equity market.

Our choice of stocks is guided by several key considerations:

-   Investment universe: Our selection is drawn from a universe of
    stocks that encompasses twenty well-established companies within the
    US equity market. These companies are known for their substantial
    market presence and are recognized leaders in their respective
    industries.

-   Market capitalization focus: We have chosen stocks with an emphasis
    on market capitalization. Larger market capitalization often
    indicates stability and lower volatility, making these stocks
    appealing for various investment strategies.

-   US equity market perspective: Our project primarily targets insights
    related to the US equity market. The chosen stocks provide a
    representative snapshot of the investment landscape in one of the
    world's largest and most influential equity markets.

-   Diversification: To create a well-rounded portfolio, we have ensured
    diversification across different sectors and industries.
    Diversification is essential in portfolio management as it spreads
    risk and mitigates overexposure to a single sector.

-   Market visibility: The selected companies are not only well-regarded
    in the financial sector but are also widely recognized in popular
    culture. Their performance is closely monitored, and they often hold
    significant sway over market indices.

-   Historical data and research: These stocks have a rich history of
    performance data and have been the subject of extensive research.
    Access to their historical data is abundant, making them suitable
    for rigorous portfolio management analysis and research.

The provided R code defines the stock tickers for these companies,
allowing you to access financial data. This data can then be employed to
conduct a range of analyses, such as return calculations, risk
assessments, and portfolio optimization, to test and implement various
investment strategies on the US equity market.

```{r}
# Define the stock tickers you want to fetch data for
stock_tickers <- c("AAPL", "MSFT", "GOOGL", "AMZN", "TSLA", "NVDA", "PYPL", "CMCSA", "ADBE", "ASML",
                   "CSCO", "PEP", "AVGO", "TMUS", "INTC", "TXN", "AMGN", "NFLX", "SBUX", "AMAT")
```

We source our data from Yahoo Finance, a highly reputable platform
renowned for its financial data. Our analysis covers a comprehensive
three-and-a-half-year period, allowing us to evaluate the performance of
our selected companies both before and after the onset of the COVID-19
pandemic.

```{r}
# Fetch historical stock data from Yahoo Finance
start_date <- "2019-01-01"  # Replace with your desired start date
end_date <- "2023-08-31"    # Replace with your desired end date
stock_data <- getSymbols(stock_tickers, from = start_date, to = end_date, auto.assign = TRUE)
```

## 1.3 Data cleaning

We perform some formatting to clean the data, an important step in
performing data analysis:

-   Extracting Adjusted Closing Prices: lapply(stock_tickers,
    function(ticker) { Ad(get(ticker)) }): This code uses the lapply
    function to retrieve the adjusted closing prices (often used for
    return calculations) for a list of stock tickers. It iterates
    through each ticker in the stock_tickers vector and fetches the
    adjusted closing prices using the Ad() function from the quantmod
    package.

-   Combining Stock Returns: do.call(cbind, stock_returns): The code
    combines the extracted adjusted closing prices into a single data
    frame by calling cbind (column-bind) on the list of stock returns
    obtained in the previous step. This creates a data frame where each
    column represents the adjusted closing prices of a specific stock.

-   Renaming Columns: colnames(fin_prices) \<- stock_tickers: The code
    assigns the stock tickers as column names to the combined data
    frame. This step ensures that each column is labeled with the
    corresponding stock ticker, making it easier to identify each
    stock's data.

-   Handling Missing Data: na.omit(fin_prices): This line of code
    removes rows with missing values (usually represented as NA) from
    the combined data frame, fin_prices. Removing missing data is a
    common preprocessing step to ensure the quality and consistency of
    the dataset for further analysis.

```{r}
# Extract adjusted closing prices (which are typically used for returns)
stock_returns <- lapply(stock_tickers, function(ticker) {
  Ad(get(ticker))
})

# Combine stock returns into a single data frame
fin_prices <- do.call(cbind, stock_returns)

# Rename columns to match your analysis
colnames(fin_prices) <- stock_tickers

# Eliminated missing data in time series
fin_return <- na.omit(fin_prices)  # Remove rows with missing values
```

We perform the arithmetic return method to compute returns for this data
set. It is simple, intuitive and widely accessible. Arithmetic returns
are particularly useful for performance measurement, providing a clear
view of actual gains and losses. It is well-suited for short-term
analysis and offer transparency.

```{r}
arith_fin_returns = diff(fin_return)/lag(fin_return)
head(arith_fin_returns, n=3)
arith_fin_returns <- arith_fin_returns[-1, ]
```

In order to ensure that the data is properly imported, with non missing
valiues and proper data cleaning procedure, we can implement this line
of code in order to learn more about data.

```{r}
plot_intro(arith_fin_returns)
```

From the figure below, Tesla's stock (TICKER: TSLA) witnessed an
unprecedented surge in attraction, making it a notable standout within
our investment universe.

Tesla's performance distinctly outpaced the broader investment universe.
The surge in retail trading interest for the electric car company can
explain to some extent this massive performance, especially in the wake
of the post-COVID market, where intensive monetary policies prompted
significant investments from both corporate and retail investors seeking
higher yields.

The code allowed us to plot returns into a time series, providing a
clear visualization of stock performance during the specified period.

```{r}
# Calculate Cumulative Returns
cumulative_returns <- cumprod(1 + arith_fin_returns)

# Plot Cumulative Return Performance
library(ggplot2)
autoplot(cumulative_returns, facets = NULL) +
  ggtitle("Cumulative Return Performance of the investment universe") +
  ylab("Cumulative Return") +
  xlab("Year")

```

We can define the minimum volatility portfolio as a portfolio of assets
with the lowest possible risk for an investor and is located on the
far-left side of the efficient frontier. Note that the minimum
volatility portfolio is also called the minimum variance portfolio or
more precisely the global minimum volatility portfolio (to distinguish
it from other optimal portfolios obtained for higher risk levels).

To implement to global minimum variance portfolio, we need to compute
the covariance matrix as an input parameter for the Markowitz
optimization model.

```{r}
cov_matrix <- cov(arith_fin_returns)

```

Correlation plays an important role in a Markowitz allocation framework,
where diversification can be achieved when allocating capital to poorly
or negatively correlated assets.

The concept of diversification seeks to enhance returns while minimizing
risk by investing in a variety of assets that will react differently to
the same event (s). For example, whenever there is unfavorable news
about a certain event, i.e. 2008 subprime mortgage crisis, the stock
market typically declines dramatically. Simultaneously, the same news
has generally benefited the price of specific assets, such as gold. As a
result, portfolio diversification should include not just diverse stocks
inside and outside of the same industry, but also diverse asset classes,
such as bonds and commodities. The diversification effect is a term that
relates to the link between portfolio correlations and diversification.
When there is an imperfect correlation between assets (positive or
negative), the diversification effect occurs. It is a critical and
successful risk mitigation method since risk mitigation may be
accomplished without sacrificing profits. As a result, any prudent
investor who is 'risk cautious' will diversify to a certain extent.

Here, we observe opportunities for diversification within our investment
universe. For instance, we notice that stocks often categorized as
defensive plays can serve as effective diversification instruments when
combined with more aggressive stocks. In this context, consider Amgen
Inc. (TICKER: AMGN) in the healthcare industry, which exhibits a neutral
correlation when compared to a stock like Tesla (TICKER: TSLA). Similar
logic applies to a stock such as PepsiCo Inc. (TICKER: PEP) in relation
to Tesla. It's worth noting that within our investment universe, we do
not find negative correlations, as all the assets exhibit some degree of
correlation to one another.

```{r}
corrplot(cor(arith_fin_returns), type='lower', 
         method = "shade", tl.col = 'black', cl.pos = "r", tl.cex = 1)
```

To further complement the analysis of the data gathered, we can run a
statistical analysis of the first moments of the distribution to assess
the performance of each stock and understand their behavior during the
timeframe observed. NB: Figures obtained from this statistical analysis
are given on a daily return basis.

```{r}
summary(arith_fin_returns)
```

In portfolio management, statistical analysis can help understand
financial patterns in data.

First, density plots, also known as probability density function plots,
serve the purpose of visualizing data distributions. They offer insights
into the shape, spread, and central tendencies of data, making them
crucial for assessing the nature of financial asset returns.

Second, QQ plots, or quantile-quantile plots, are utilized to evaluate
whether a dataset adheres to a specific theoretical distribution, such
as the normal distribution. These plots help portfolio managers identify
departures from expected distributions, facilitating informed investment
decisions. Together, these techniques aid in the exploration and
assessment of financial data, enabling portfolio managers to make more
informed and data-driven choices in their investment strategies.

We can run some more advanced statistical analysis to understand the
asset return behavior of the equities selected in this analysis.

```{r}

# Advanced statistical analysis for the dataset

#plot_density(arith_fin_returns)
plot_qq(arith_fin_returns)

```

# 2. Modelling part

Modern Portfolio Theory (MPT) is founded on several market and investor
assumptions. Several of these assumptions are stated explicitly, while
others are implied. Markowitz's contributions to (MPT) in portfolio
selection are based on the following basic assumptions:Â 

-   Investors are rational (they seek to maximize returns while
    minimizing risk, or minimize risk while maximize return).

-   Investors will accept increased risk only if compensated with higher
    expected returns.

-   Investors receive all relevant information regarding their
    investment decision.

-   Investors can borrow or lend an unlimited amount of capital at a
    risk-free rate of interest.

## 2.1 Unbiased Global Minimum Variance (GMV) portfolio

In the context of time series data analysis, one of the crucial
applications is the division of the data set into a training set and a
testing set based on temporal order. This approach is particularly
important when dealing with data that evolves over time, such as stock
prices, weather observations, or economic indicators.

The training set typically comprises historical data, while the testing
set contains more recent observations. This temporal separation allows
for the evaluation of predictive models and forecasting techniques. By
using historical data to train the model and then assessing its
performance on more recent data, analysts can gauge the model's ability
to make accurate predictions and anticipate future trends. Time series
data applications are essential in fields like finance, where
understanding and forecasting trends over time is important.

For the purpose of modelling, we will shrink the data set into two
different sub-samples. We can define the following parameters:

```{r}
num_rows_subsample1 <- 400
total_rows <- nrow(arith_fin_returns)
```

1.  The first sub-sample will cover the first 400 trading days covered
    in the data set.

```{r}
subsample1 <- arith_fin_returns[1:num_rows_subsample1, ]
plot_intro(subsample1)
```

2.  The second sub-sample will cover the rest of the data set, covering
    the equivalent of 773 trading days.

```{r}
subsample2 <- arith_fin_returns[(num_rows_subsample1 + 1):total_rows, ]
plot_intro(subsample2)

```

We implement the parameters of the model in order to compute the GMV:

```{r}

#Definition of parameters
n <- ncol(subsample1)
T <- nrow(subsample1)
e <- rep(1, n)
perio <- 12

#Compute Sigma (unbiased covariance matrix)
Sigma <- cov(subsample1) * (T - 1) / (T - n - 2) * perio
C <- t(e) %*% solve(Sigma) %*% e

#Anticipated volatility can be computed
sigmag <- sqrt(1 / C)
```

After computing the parameters required to implement the unbiased GMV
portfolio, we can compute omega, representing the weightings of the
portfolio as follows.

```{r}
omega_gmv <- 1 / as.numeric(C) * solve(Sigma) %*% e
```

We can see in this instance that the portfolio is mixed, with some long
and short positions. The capital is fully invested, with some important
exposure in the long part of the portfolio on stocks like Amazon
(TICKER: AMZN) with 39.85%, followed by PepsiCo (TICKER: PEP) at 29.45%
and ASML (TICKER: ASML) at 26.35%.

On the short part of the portfolio, we can see an important short on
three stocks that can stand out: Applied Materials Inc. (TICKER: AMAT)
-24.07%, Adobe (TICKER: ADBE) at -19.90% and NVIDIA Corp. (TICKER:
NVDIA) at -18.28%.

```{r}
barplot(as.numeric(omega_gmv), col = 'black', ylim = c(-1, 1))
```

## 2.2 Implementation of Principal Component Analysis (PCA)

Principal Component Analysis (PCA) is a technique used to analyze and
reduce the dimensionality of a dataset while retaining as much variance
as possible. We perform the PCA analysis using the second subsample
starting from the trading day number 401 of the sample to the trading
day number 1174.

```{r}
pca_result <- prcomp(subsample2, center = TRUE, scale = TRUE)

#Extract principal component loadings
loadings <- pca_result$rotation

#Variance explained by each principal component
var_explained <- (pca_result$sdev^2) / sum(pca_result$sdev^2)

#We select the number of components for the PCA
num_components <- 3  # Adjust as needed

#We compute the weights of the PCA in the portfolio.
weights_pca <- loadings[, 1:num_components] / rowSums(loadings[, 1:num_components])
```

This is the result of the plot from the PCA analysis. In the context of
your PCA results for the twenty US equity stocks, here are some
interpretations:

1.  **Principal Components (PCs)**:

    -   PC1, PC2, and PC3 represent the first, second, and third
        principal components, respectively.

    -   Each principal component is a linear combination of the original
        variables (in this case, stocks) such that it captures the
        maximum variance in the data. PC1 captures the most variance,
        followed by PC2, and so on.

2.  **Loadings**:

    -   Loadings represent the coefficients that define the contribution
        of each original variable (stock) to the principal component.
        The loadings are specific to each PC.

    -   Positive or negative values in loadings indicate the direction
        and strength of the relationship between each stock and the
        principal component. For example, a high positive loading
        indicates that a particular stock has a strong positive
        influence on the corresponding principal component.

3.  **Weights for the PCA Portfolio**:

    -   The weights for the PCA portfolio represent the portfolio
        allocation to each stock based on the chosen principal
        components. These weights can be used to create a portfolio with
        a specific strategy, which leverages the information in the
        principal components.

    -   In your code, you've selected the first three principal
        components (num_components = 3), and you've calculated the
        weights for each stock based on these components.

4.  **Interpretation**:

    -   PC1, PC2, and PC3 capture specific patterns or relationships in
        the returns of the stocks. For example, PC1 might capture broad
        market movements, while PC2 might capture sector-specific
        trends.

    -   The specific interpretation of each PC depends on the loadings
        and how they relate to the original variables (stocks). Positive
        loadings indicate stocks that move in the same direction as the
        principal component, while negative loadings suggest stocks that
        move in the opposite direction.

    -   By examining the loadings for each PC, you can gain insights
        into which stocks are the most influential for each component.

```{r}
my_colors <- c("red", "blue", "green") # vector of colours
barplot(weights_pca, beside = TRUE, col = my_colors,
        names.arg = colnames(weights_pca),
        legend.text = colnames(weights_pca), 
        main = "PCA Portfolio Weights")
```
